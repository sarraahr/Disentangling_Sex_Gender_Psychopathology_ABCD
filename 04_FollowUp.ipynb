{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fcdc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helper import *\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef3042",
   "metadata": {},
   "source": [
    "This is just an exploratory file to investigate the different structures of the follow up data and see how much the factor score correlate over the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25464b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain only data that has all the follow ups\n",
    "all_data = abcd_data(measurement = 'all')\n",
    "all_data_nomv = prepare_data(all_data, threshold=1)\n",
    "all_data_followups = get_data_with_followups(all_data_nomv, '2y_follow_up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bbabb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = abcd_data(measurement = 'baseline', load = False, df = all_data_followups)\n",
    "baseline_1 = prepare_data(baseline)\n",
    "item_list = filter_polychoric_corr(baseline_1, print_corr = False)\n",
    "\n",
    "aggregates_baseline = {\"cbcl_q8182_Steals\": ['cbcl_q81_p', 'cbcl_q82_p'], \n",
    "                  \"cbcl_q165797_Threatens/Bullies/Attacks\": ['cbcl_q16_p', 'cbcl_q97_p', 'cbcl_q37_p', 'cbcl_q57_p'],\n",
    "                  \"cbcl_q56cf_Stomach_Issues\":['cbcl_q56c_p', 'cbcl_q56f_p'],\n",
    "                  \"cbcl_q5355_Weight_Problems\":['cbcl_q53_p', 'cbcl_q55_p'],\n",
    "                  \"cbcl_q4070_Hallucinations\": ['cbcl_q70_p', 'cbcl_q40_p'],\n",
    "                  \"cbcl_q2548_Peer_Problems\": ['cbcl_q25_p', 'cbcl_q48_p'],\n",
    "                  \"cbcl_q222328_Disobeys_Rules\": ['cbcl_q28_p', 'cbcl_q23_p', 'cbcl_q22_p'],\n",
    "                  \"cbcl_q21106_Destroys\": ['cbcl_q20_p', 'cbcl_q106_p', 'cbcl_q21_p'],\n",
    "                  \"cbcl_q081078_Distracted/Hyperactive\": ['cbcl_q10_p', 'cbcl_q78_p', 'cbcl_q08_p'],\n",
    "                  \"cbcl_q5960_SexPlay\": ['cbcl_q59_p', 'cbcl_q60_p']}\n",
    "\n",
    "baseline_2 = aggregate_items(baseline_1, item_list, aggregates_baseline)\n",
    "data_poly_corr = common.polychoric.polychoric_correlation_serial(get_question_items(baseline_2, 'cbcl_').to_numpy().T,0,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "030f6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "followup1year = abcd_data(measurement = '1y_follow_up', load = False, df = all_data_followups)\n",
    "followup1year_1 = prepare_data(followup1year)\n",
    "item_list_fu = filter_polychoric_corr(followup1year_1, print_corr = False)\n",
    "\n",
    "aggregates_followup1year = {\"cbcl_q8182_Steals\": ['cbcl_q81_p', 'cbcl_q82_p'], \n",
    "                  \"cbcl_q165797_Attacks/Threatens\": ['cbcl_q57_p', 'cbcl_q97_p'],\n",
    "                  \"cbcl_q56cf_Stomach_Issues\":['cbcl_q56c_p', 'cbcl_q56f_p'],\n",
    "                  \"cbcl_q5355_Weight_Problems\":['cbcl_q53_p', 'cbcl_q55_p'],\n",
    "                  \"cbcl_q4070_Hallucinations\": ['cbcl_q70_p', 'cbcl_q40_p'],\n",
    "                  \"cbcl_q253848_Peer_Problems\": ['cbcl_q25_p', 'cbcl_q48_p', 'cbcl_q38_p'],\n",
    "                  \"cbcl_q222328_Disobeys_Rules\": ['cbcl_q28_p', 'cbcl_q23_p', 'cbcl_q22_p'],\n",
    "                  \"cbcl_q21106_Destroys\": ['cbcl_q20_p', 'cbcl_q106_p', 'cbcl_q21_p'],\n",
    "                  \"cbcl_q081078_Distracted/Hyperactive\": ['cbcl_q10_p', 'cbcl_q78_p', 'cbcl_q08_p'],\n",
    "                  \"cbcl_q5960_SexPlay\": ['cbcl_q59_p', 'cbcl_q60_p'],\n",
    "                  \"cbcl_q8485_Strangeness\": ['cbcl_q84_p', 'cbcl_q85_p']}\n",
    "\n",
    "\n",
    "followup1year_2 = aggregate_items(followup1year_1, item_list_fu, aggregates_followup1year)\n",
    "data_poly_corr_fu = common.polychoric.polychoric_correlation_serial(get_question_items(followup1year_2, 'cbcl_').to_numpy().T,0,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00953d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "followup2year = abcd_data(measurement = '2y_follow_up', load = False, df = all_data_followups)\n",
    "followup2year_1 = prepare_data(followup2year)\n",
    "item_list_fu2 = filter_polychoric_corr(followup2year_1, print_corr = False)\n",
    "\n",
    "aggregates_followup2year = {\"cbcl_q8182_Steals\": ['cbcl_q81_p', 'cbcl_q82_p'], \n",
    "                  \"cbcl_q165797_Attacks/Threatens\": ['cbcl_q57_p', 'cbcl_q97_p'],\n",
    "                  \"cbcl_q56cf_Stomach_Issues\":['cbcl_q56c_p', 'cbcl_q56f_p'],\n",
    "                  \"cbcl_q5355_Weight_Problems\":['cbcl_q53_p', 'cbcl_q55_p'],\n",
    "                  \"cbcl_q4070_Hallucinaitons\": ['cbcl_q70_p', 'cbcl_q40_p'],\n",
    "                  \"cbcl_q253848_Peer_Problems\": ['cbcl_q25_p', 'cbcl_q48_p', 'cbcl_q38_p'],\n",
    "                  \"cbcl_q222328_Disobeys_Rules\": ['cbcl_q28_p', 'cbcl_q23_p', 'cbcl_q22_p'],\n",
    "                  \"cbcl_q21106_Destroys\": ['cbcl_q20_p', 'cbcl_q106_p', 'cbcl_q21_p'],\n",
    "                  \"cbcl_q081078_Distracted/Hyperactive\": ['cbcl_q10_p', 'cbcl_q78_p', 'cbcl_q08_p'],\n",
    "                  \"cbcl_q5960_SexPlay\": ['cbcl_q59_p', 'cbcl_q60_p'],\n",
    "                  \"cbcl_q8485_Strangeness\": ['cbcl_q84_p', 'cbcl_q85_p'],\n",
    "                  \"cbcl_q1891_Self_Harm\": ['cbcl_q18_p', 'cbcl_q91_p'],\n",
    "                  \"cbcl_q222328_Disobedience\": ['cbcl_q22_p', 'cbcl_q23_p','cbcl_q28_p']}\n",
    "\n",
    "\n",
    "followup2year_2 = aggregate_items(followup2year_1, item_list_fu2, aggregates_followup2year)\n",
    "data_poly_corr_fu2 = common.polychoric.polychoric_correlation_serial(get_question_items(followup2year_2, 'cbcl_').to_numpy().T,0,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31488004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#followup3year = abcd_data(measurement = '3y_follow_up', load = False, df = all_data_followups)\n",
    "#followup3year_1 = prepare_data(followup3year)\n",
    "#item_list_fu3 = filter_polychoric_corr(followup3year_1, print_corr = True)\n",
    "\n",
    "#aggregates_followup3year = {\"cbcl_q8182_Steals\": ['cbcl_q81_p', 'cbcl_q82_p'], \n",
    "                  #\"cbcl_q165797_Attacks/Threatens\": ['cbcl_q57_p', 'cbcl_q97_p'],\n",
    "                  #\"cbcl_q56cf_Stomach_Issues\":['cbcl_q56c_p', 'cbcl_q56f_p'],\n",
    "                  #\"cbcl_q5355_Weight_Problems\":['cbcl_q53_p', 'cbcl_q55_p'],\n",
    "                  #\"cbcl_q253848_Peer_Problems\": ['cbcl_q25_p', 'cbcl_q48_p', 'cbcl_q38_p'],\n",
    "                  #\"cbcl_q222328_Disobeys_Rules\": ['cbcl_q28_p', 'cbcl_q23_p', 'cbcl_q22_p', 'cbcl_q43_p' ],\n",
    "                  #\"cbcl_q2021_Destroys\": ['cbcl_q20_p', 'cbcl_q21_p'],\n",
    "                  #\"cbcl_q081078_Distracted/Hyperactive\": ['cbcl_q10_p', 'cbcl_q78_p', 'cbcl_q08_p'],\n",
    "                  #\"cbcl_q5960_SexPlay\": ['cbcl_q96_p', 'cbcl_q60_p'],\n",
    "                  #\"cbcl_q8485_Strangeness\": ['cbcl_q84_p', 'cbcl_q85_p'],\n",
    "                  #\"cbcl_q1891_Self_Harm\": ['cbcl_q18_p', 'cbcl_q91_p'],\n",
    "                  #\"cbcl_q222328_Disobedience\": ['cbcl_q22_p', 'cbcl_q23_p','cbcl_q28_p'],\n",
    "                  #\"cbcl_q72106_Vandalism/FireSetting\": ['cbcl_q72_p', 'cbcl_q106_p'],\n",
    "                  #\"cbcl_q8687_Irritability\": ['cbcl_q86_p', 'cbcl_q87_p']}\n",
    "\n",
    "\n",
    "#followup3year_2 = aggregate_items(followup3year_1, item_list_fu3, aggregates_followup3year)\n",
    "#data_poly_corr_fu3 = common.polychoric.polychoric_correlation_serial(get_question_items(followup3year_2, 'cbcl_').to_numpy().T,0,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495ce142",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_factor_scores, bl_rotated_loadings = get_EFA_structure(baseline_2, 6, 'geomin_obl', run_again = False)\n",
    "subjectsList_df = baseline_2[\"src_subject_id\"].values\n",
    "bl_factor_scores['src_subject_id'] = subjectsList_df\n",
    "baseline_scores = bl_factor_scores.sort_values(by=['src_subject_id'])\n",
    "baseline_scores_X = baseline_scores[[0,1,2,3,4,5]].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b2b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fu1_factor_scores, fu1_rotated_loadings = get_EFA_structure(followup1year_2, 6, 'geomin_obl', run_again = False)\n",
    "subjectsList_df = followup1year_2[\"src_subject_id\"].values\n",
    "fu1_factor_scores['src_subject_id'] = subjectsList_df\n",
    "fu1_scores = fu1_factor_scores.sort_values(by=['src_subject_id'])\n",
    "fu1_scores_Y = fu1_scores[[0,1,2,3,4,5]].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f24d78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fu2_factor_scores, fu2_rotated_loadings = get_EFA_structure(followup2year_2, 6, 'geomin_obl', run_again = False)\n",
    "subjectsList_df = followup2year_2[\"src_subject_id\"].values\n",
    "fu2_factor_scores['src_subject_id'] = subjectsList_df\n",
    "fu2_scores = fu2_factor_scores.sort_values(by=['src_subject_id'])\n",
    "fu2_scores_Y = fu2_scores[[0,1,2,3,4,5]].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a771c6",
   "metadata": {},
   "source": [
    "### Baseline and 1 year follow up\n",
    "Predict Factor Score from Baseline to 1 year follow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4448b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = LinearRegression() # initialize the model\n",
    "scores = cross_validate(my_model, baseline_scores_X, fu1_scores_Y, cv = 100)\n",
    "model_fit = my_model.fit(baseline_scores_X, fu1_scores_Y)\n",
    "test_scores = scores[\"test_score\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "395c3b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3531208871651132"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26acc853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11478511117779387"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit.coef_.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74579e8",
   "metadata": {},
   "source": [
    "### Baseline and 2 year follow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28232cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = LinearRegression() # initialize the model\n",
    "scores = cross_validate(my_model, baseline_scores_X, fu2_scores_Y, cv = 100)\n",
    "model_fit = my_model.fit(baseline_scores_X, fu2_scores_Y)\n",
    "test_scores = scores[\"test_score\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "086abc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27547338071433886"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f49ab200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10106076022797078"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit.coef_.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7de9a",
   "metadata": {},
   "source": [
    "### 1 year follow up and 2 year follow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcf31bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = LinearRegression() # initialize the model\n",
    "scores = cross_validate(my_model, fu1_scores_Y, fu2_scores_Y, cv = 100)\n",
    "model_fit = my_model.fit(fu1_scores_Y, fu2_scores_Y)\n",
    "test_scores = scores[\"test_score\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6a7d534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3549933523193865"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "155da20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1132829168096993"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit.coef_.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
